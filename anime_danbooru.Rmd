---
title: "danbooru tag poster"
author: "Yehong Deng"
date: "2024-02-27"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(stringr)
library(sna)
library(igraph)
library(sand)
library(network)
library(igraphdata)
library(tidyverse)
library(splitstackshape)
library(reshape2)
library(qdapTools)
library(tidyr)
library(blockmodels)
library(sbm)
library(tidyverse)
library(tidygraph)
library(ggraph)
library(reshape2)
library(cluster)
library(circlize)
library(ggsankey)
library(RColorBrewer)
library(latentnet)
# To set current folder as your working directory.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

```{r}
# Read the data
danbooru_in_month <- read.csv("image_in_month.csv")

# filter the data to only include the data in the last hour
danbooru_in_hour <- danbooru_in_month %>%
  filter(created_at <= 3600 + 1264803292) 

#filter the top 1000 score images
danbooru_top_rating <- danbooru_in_month %>%
  top_n(1000, score)
```

```{r}
# clean the tags
id_tag_list <- danbooru_in_hour %>% 
  select(id, tags)

# clean the tags remove the punctuation and stopwords
corpus <- Corpus(VectorSource(id_tag_list$tags))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))

# assign the cleaned text back to the dataframe
cleaned_text <- sapply(corpus, function(x) paste(unlist(str_split(x, "\\s+")), collapse = " "))
id_tag_list$tags <- cleaned_text
```

```{r}
# text clean for the top 1000 score images
id_tag_list_top <- danbooru_top_rating %>% 
  select(id, tags)

corpus_top <- Corpus(VectorSource(id_tag_list_top$tags))
corpus_top <- tm_map(corpus_top, content_transformer(tolower))
corpus_top <- tm_map(corpus_top, removePunctuation)
corpus_top <- tm_map(corpus_top, removeWords, stopwords("english"))

cleaned_text_top <- sapply(corpus_top, function(x) paste(unlist(str_split(x, "\\s+")), collapse = " "))
id_tag_list_top$tags <- cleaned_text_top
```



```{r}
# create occurances matrix
temp <- crossprod(
  as.matrix(
    cSplit_e(id_tag_list, "tags", " ", type = "character", 
             fill = 0, drop = TRUE)[-1]))

temp[upper.tri(temp, diag = TRUE)] <- NA

# create edge list
edge_list_df <- melt(temp, na.rm = TRUE) %>% 
  filter(value != 0) %>%
  mutate(from = gsub("tags_", "", Var1),
         to = gsub("tags_", "", Var2),
         weight = value) %>%
  select(c("from", "to", "weight"))
```

```{r}
# create co-occurrence matrix for the top 1000 score images
temp_top <- crossprod(
  as.matrix(
    cSplit_e(id_tag_list_top, "tags", " ", type = "character", 
             fill = 0, drop = TRUE)[-1]))

temp_top[upper.tri(temp_top, diag = TRUE)] <- NA

# create edge list for the top 1000 score images
edge_list_df_top <- melt(temp_top, na.rm = TRUE) %>% 
  filter(value != 0) %>%
  mutate(from = gsub("tags_", "", Var1),
         to = gsub("tags_", "", Var2),
         weight = value) %>%
  select(c("from", "to", "weight"))
```



```{r}
# filter the edge list to only include the top 100 most frequent tags
top_100 <- edge_list_df %>%
  count(from, sort = TRUE) %>% # 对column_name列中的词进行计数并排序
  top_n(100) %>% # 选出出现次数最多的15个词
  arrange(desc(n))
# change top_50 to a list
top_100_list <- top_100$from

edge_list_df_100 <- edge_list_df %>%
  filter(from %in% top_100_list) %>%
  filter(to %in% top_100_list)
```

```{r}
# filter the edge list to only include the top 100 most frequent tags for the top 1000 score images
top_100_top <- edge_list_df_top %>%
  count(from, sort = TRUE) %>% # 对column_name列中的词进行计数并排序
  top_n(100) %>% # 选出出现次数最多的15个词
  arrange(desc(n))

top_100_list_top <- top_100_top$from

edge_list_df_100_top <- edge_list_df_top %>%
  filter(from %in% top_100_list_top) %>%
  filter(to %in% top_100_list_top)

```


```{r}
# create the graph for network analysis
anime <-graph_from_data_frame(edge_list_df_100, directed = FALSE)
l <- layout.kamada.kawai(anime)

plot(anime,vertex.label = NA,layout=l, vertex.size = 3)
```

```{r}
# create the graph for network analysis for the top 1000 score images
anime_top <-graph_from_data_frame(edge_list_df_100_top, directed = FALSE)
plot(anime_top,vertex.label = NA,layout=layout.fruchterman.reingold, vertex.size = 3)
```


```{r}
# SBM model for clustering
## extraxt the adjacency matrix
anime.adj <- as_adj(anime, sparse = FALSE)

# fit the block model
anime_out <- BM_poisson("SBM", anime.adj)
str(anime_out)
anime_out$estimate()

# find the best fit number of clusters 
which.max(anime_out$ICL)

# extract the best fit membership probabilities
best_fit_membership_probs <- anime_out$memberships[[which.max(anime_out$ICL)]]$Z
clust_assignments <- apply(best_fit_membership_probs, 1, which.max)

# clust assignments
plot(anime,
     vertex.color = clust_assignments,
     vertex.label = NA,layout=l, vertex.size = 3)

# add the cluster assignments to the graph
V(anime)$membership <- clust_assignments 

# subgraph of each of the three clusters
subgraph_1 <- induced_subgraph(anime, V(anime)[membership == 1])
subgraph_2 <- induced_subgraph(anime, V(anime)[membership == 2])
subgraph_3 <- induced_subgraph(anime, V(anime)[membership == 3])


# plot the subgraphs
plot(subgraph_1, vertex.size = 10 * sqrt(authority.score(anime)$vector), layout=layout.kamada.kawai)
plot(subgraph_2, vertex.size = 10 * sqrt(authority.score(anime)$vector), layout=layout.kamada.kawai)
plot(subgraph_3, vertex.size = 10 * sqrt(authority.score(anime)$vector), layout=layout.kamada.kawai)

```

```{r}
# SBM model for clustering for the top 1000 score images
## extraxt the adjacency matrix
anime_top.adj <- as_adj(anime_top, sparse = FALSE)

# fit the block model
anime_top_out <- BM_poisson("SBM", anime_top.adj)
str(anime_top_out)
anime_top_out$estimate()

# find the best fit number of clusters
which.max(anime_top_out$ICL)

# extract the best fit membership probabilities
best_fit_membership_probs_top <- anime_top_out$memberships[[which.max(anime_top_out$ICL)]]$Z
clust_assignments_top <- apply(best_fit_membership_probs_top, 1, which.max)

# clust assignments
plot(anime_top,
     vertex.color = clust_assignments_top,
     vertex.label = NA,layout=layout.fruchterman.reingold, vertex.size = 3)

# add the cluster assignments to the graph
V(anime_top)$membership <- clust_assignments_top

# subgraph of each of the three clusters
subgraph_1_top <- induced_subgraph(anime_top, V(anime_top)[membership == 1])
subgraph_2_top <- induced_subgraph(anime_top, V(anime_top)[membership == 2])
subgraph_3_top <- induced_subgraph(anime_top, V(anime_top)[membership == 3])
subgraph_4_top <- induced_subgraph(anime_top, V(anime_top)[membership == 4])
subgraph_5_top <- induced_subgraph(anime_top, V(anime_top)[membership == 5])

#plot the subgraphs
plot(subgraph_1_top, vertex.size = 10 * sqrt(authority.score(anime_top)$vector), layout=layout.fruchterman.reingold)
plot(subgraph_2_top, vertex.size = 10 * sqrt(authority.score(anime_top)$vector), layout=layout.fruchterman.reingold)
plot(subgraph_3_top, vertex.size = 10 * sqrt(authority.score(anime_top)$vector), layout=layout.fruchterman.reingold)
plot(subgraph_4_top, vertex.size = 10 * sqrt(authority.score(anime_top)$vector), layout=layout.fruchterman.reingold)
plot(subgraph_5_top, vertex.size = 10 * sqrt(authority.score(anime_top)$vector), layout=layout.fruchterman.reingold)


```



```{r}
## setting the pal
pal <- c("#db5f57", "#db8557", "#dbaa57", "#dbd057", "#c0db57", "#9bdb57", "#75db57", "#57db5f", "#57db85", "#57dbaa", "#57dbd0", "#57c0db", "#579bdb", "#5775db", "#5f57db", "#8557db", "#aa57db", "#d057db", "#db57c0", "#db579b", "#db5775")
```


```{r}
# Extract 3 node lists
member_1 <- V(subgraph_1)$name
member_2 <- V(subgraph_2)$name
member_3 <- V(subgraph_3)$name
```

```{r}
# extract node lists for the top 1000 score images
member_1_top <- V(subgraph_1_top)$name
member_2_top <- V(subgraph_2_top)$name
member_3_top <- V(subgraph_3_top)$name
member_4_top <- V(subgraph_4_top)$name
member_5_top <- V(subgraph_5_top)$name
```


```{r}
#Create 3 edge lists for 3 subgraphs
sub_edge_list_1 <- edge_list_df_100 %>%
  filter(from %in% member_1) %>%
  filter(to %in% member_1)

sub_edge_list_2 <- edge_list_df_100 %>%
  filter(from %in% member_2) %>%
  filter(to %in% member_2)

sub_edge_list_3 <- edge_list_df_100 %>%
  filter(from %in% member_3) %>%
  filter(to %in% member_3)
```
 
```{r}
#Create 5 edge lists for 3 subgraphs for the top 1000 score images
sub_edge_list_1_top <- edge_list_df_100_top %>%
  filter(from %in% member_1_top) %>%
  filter(to %in% member_1_top)

sub_edge_list_2_top <- edge_list_df_100_top %>%
  filter(from %in% member_2_top) %>%
  filter(to %in% member_2_top)

sub_edge_list_3_top <- edge_list_df_100_top %>%
  filter(from %in% member_3_top) %>%
  filter(to %in% member_3_top)

sub_edge_list_4_top <- edge_list_df_100_top %>%
  filter(from %in% member_4_top) %>%
  filter(to %in% member_4_top)

sub_edge_list_5_top <- edge_list_df_100_top %>%
  filter(from %in% member_5_top) %>%
  filter(to %in% member_5_top)
```



```{r}
# Create 3 sankey dataframes for 3 subgraphs
sub_1_sankey <- sub_edge_list_1 %>%
  ggsankey::make_long(from, to, value = weight)

sub_2_sankey <- sub_edge_list_2 %>%
  ggsankey::make_long(from, to, value = weight)

sub_3_sankey <- sub_edge_list_3 %>%
  ggsankey::make_long(from, to, value = weight)
```
 
```{r}
# Create 3 sankey dataframes for 3 subgraphs for the top 1000 score images
sub_1_sankey_top <- sub_edge_list_1_top %>%
  ggsankey::make_long(from, to, value = weight)

sub_2_sankey_top <- sub_edge_list_2_top %>%
  ggsankey::make_long(from, to, value = weight)

sub_3_sankey_top <- sub_edge_list_3_top %>%
  ggsankey::make_long(from, to, value = weight)

sub_4_sankey_top <- sub_edge_list_4_top %>%
  ggsankey::make_long(from, to, value = weight)

sub_5_sankey_top <- sub_edge_list_5_top %>%
  ggsankey::make_long(from, to, value = weight)

```


 
 
```{r}
# ## Do sankey for subgraph 1
# ggplot(
#   sub_1_sankey,
#   aes(
#     x = x,
#     next_x = next_x,
#     node = node,
#     next_node = next_node,
#     value = value,
#     fill = node
#   )
# ) +
#   geom_sankey(flow.alpha = 0.6,
#               width = 0.01) +
#   
#   theme_sankey() +
#   labs(x = NULL) +
#   theme(legend.position = "none") +
#   scale_x_discrete(labels = c("Genre_1", "Genre_2")) +
#   geom_sankey_text(
#     data = filter(sub_1_sankey, x == "from"),
#     aes(label = paste0(node, "   "), color = node),
#     hjust = 1
#   ) +
#   geom_sankey_text(
#     data = filter(sub_1_sankey, x== "to"),
#     aes(label = paste0("   ", node), color = next_node),
#     hjust = 0
#   )





## Do sankey for subgraph 2
ggplot(
  sub_2_sankey,
  aes(
    x = x,
    next_x = next_x,
    node = node,
    next_node = next_node,
    value = value,
    fill = node
  )
) +
  geom_sankey(flow.alpha = 0.6,
              width = 0.01) +
  scale_fill_manual(values = pal) +
  theme_sankey() +
  labs(x = NULL) +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("Genre_1", "Genre_2")) +
  geom_sankey_text(
    data = filter(sub_2_sankey, x == "from"),
    aes(label = paste0(node, "   "), color = node),
    hjust = 1
  ) +
  geom_sankey_text(
    data = filter(sub_2_sankey, x == "to"),
    aes(label = paste0("   ", node), color = node),
    hjust = 0
  ) 



## Archive for a success version
  # ggplot(
  #   Danbooru_sankey,
  #   aes(
  #     x = x,
  #     next_x = next_x,
  #     node = node,
  #     next_node = next_node,
  #     value = value,
  #     fill = node
  #   )
  # ) +
  # geom_sankey(flow.alpha = 0.6,
  #             width = 0.01) +
  # scale_fill_manual(values = pal) +
  # theme_sankey() +
  # labs(x = NULL) +
  # theme(legend.position = "none") +
  # scale_x_discrete(labels = c("Genre_1", "Genre_2")) +
  # geom_sankey_text(
  #   data = filter(Danbooru_sankey, x == "from"),
  #   aes(label = paste0(node, "   "), color = node),
  #   hjust = 1
  # ) +
  # geom_sankey_text(
  #   data = filter(Danbooru_sankey, x == "to"),
  #   aes(label = paste0("   ", node), color = node),
  #   hjust = 0
  # ) +
  # scale_color_manual(values = pal)
 

## Do sankey for subgraph 3
ggplot(
  sub_3_sankey,
  aes(
    x = x,
    next_x = next_x,
    node = node,
    next_node = next_node,
    value = value,
    fill = node
  )
) +
  geom_sankey(flow.alpha = 0.6,
              width = 0.01) +
  scale_fill_manual(values = pal) +
  theme_sankey() +
  labs(x = NULL) +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("Genre_1", "Genre_2")) +
  geom_sankey_text(
    data = filter(sub_3_sankey, x == "from"),
    aes(label = paste0(node, "   "), color = node),
    hjust = 1
  ) +
  geom_sankey_text(
    data = filter(sub_3_sankey, x == "to"),
    aes(label = paste0("   ", node), color = node),
    hjust = 0
  ) 


```


```{r}
## Do sankey for subgraph 1_top
ggplot(
  sub_5_sankey_top,
  aes(
    x = x,
    next_x = next_x,
    node = node,
    next_node = next_node,
    value = value,
    fill = node
  )
) +
  geom_sankey(flow.alpha = 0.6,
              width = 0.01) +
  theme_sankey() +
  labs(x = NULL) +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("Genre_1", "Genre_2")) +
  geom_sankey_text(
    data = filter(sub_5_sankey_top, x == "from"),
    aes(label = paste0(node, "   "), color = node),
    hjust = 1
  ) +
  geom_sankey_text(
    data = filter(sub_5_sankey_top, x == "to"),
    aes(label = paste0("   ", node), color = node),
    hjust = 0
  ) 
```




```{r}
# # Since the sankey plot is not very informative, we can use the chord diagram to visualize the relationship for subgraph1
# # Use the chorddiag package to visualize the relationship between the genres
# 
# 
# chord_Sub_1 <- sub_edge_list_1 %>%
#   group_by(from, to) %>%
#   summarize(flowTotal = sum(weight, na.rm = TRUE)) %>%
#   ungroup() 
# 
# chordDiagram(chord_Sub_1)


# Do the same to subgraph 2
chord_Sub_2 <- sub_edge_list_2 %>%
  # filter out the tagme tag
  filter(!from %in% "tagme",!to %in% "tagme") %>%
  group_by(from, to) %>%
  summarize(flowTotal = sum(weight, na.rm = TRUE)) %>%
  ungroup() 

chordDiagram(chord_Sub_2)
```


```{r}
anime_fit <- ergmm(edge_list_df_100_top ~ euclidean(d=2,G=3),family = "Poisson")
plot(anime_fit, pie = TRUE)
```

```{r})
```







